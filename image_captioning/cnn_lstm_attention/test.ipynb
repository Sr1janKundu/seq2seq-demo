{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d773d7f4-0587-47e8-a86e-651f9021f8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srijan\\anaconda3\\envs\\diffusion_1\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import v2\n",
    "import cv2\n",
    "from torchvision.models import (densenet121, DenseNet121_Weights,\n",
    "                                densenet161, DenseNet161_Weights,\n",
    "                                resnet50, ResNet50_Weights,\n",
    "                                resnet152, ResNet152_Weights, \n",
    "                                vgg19, VGG19_Weights)\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.datasets import CocoCaptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21bc143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\cnn_lstm_attention'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7a18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_img = \"C:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\COCO2014\\\\train2014\"\n",
    "val_root_img = \"C:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\COCO2014\\\\val2014\"\n",
    "train_captions = \"C:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\COCO2014\\\\annotations_trainval2014\\\\annotations\\\\captions_train2014.json\"\n",
    "val_captions = \"C:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\COCO2014\\\\annotations_trainval2014\\\\annotations\\\\captions_val2014.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9792e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_album = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(224, 224, interpolation=cv2.INTER_AREA),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        A.pytorch.ToTensorV2()], p=1.\n",
    "    ),\n",
    "    \"test\": A.Compose([\n",
    "        A.Resize(224, 224, interpolation=cv2.INTER_AREA),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        A.pytorch.ToTensorV2()], p=1.\n",
    "    )\n",
    "}\n",
    "\n",
    "trans_v2 = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9208458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f3631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = Image.open(os.path.join(train_root_img, os.listdir(train_root_img)[0])).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536bcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152_net = resnet152(weights = ResNet152_Weights.DEFAULT)\n",
    "resnet152_net = nn.Sequential(*list(resnet152_net.children())[:-2]).to(device)\n",
    "resnet152_dim = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3448fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 224, 224]), torch.Size([1, 3, 224, 224]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_trans_album = trans_album[\"train\"](image = np.array(img0, dtype = np.float32))[\"image\"].to(device).unsqueeze(0)\n",
    "img0_trans_v2 = trans_v2(img0).to(device).unsqueeze(0)\n",
    "img0_trans_album.size(), img0_trans_v2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eedcced5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 7, 7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_res152 = resnet152_net(img0_trans_album)\n",
    "img0_res152.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2969998c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 7, 2048])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_res152 = img0_res152.permute(0, 2, 3, 1)\n",
    "img0_res152.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeeecbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 49, 2048])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_res152 = img0_res152.view(img0_res152.size(0), -1, img0_res152.size(-1))\n",
    "img0_res152.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e535cdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(albumentations.core.composition.Compose,\n",
       " torchvision.transforms.v2._container.Compose)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trans_album[\"train\"]), type(trans_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d44ca7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trans_album[\"train\"]) == A.core.composition.Compose, type(trans_v2) == v2._container.Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be122767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coco_dataloader(\n",
    "    transform,\n",
    "    root: str,\n",
    "    annFile: str,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 4\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a DataLoader for COCO Captions using torchvision's built-in dataset.\n",
    "    \n",
    "    Args:\n",
    "        root: Path to the COCO images directory\n",
    "        annFile: Path to the annotations json file\n",
    "        batch_size: Number of samples per batch\n",
    "        num_workers: Number of worker processes for data loading\n",
    "    \"\"\"\n",
    "    # Define transforms\n",
    "    transform = v2.Compose([\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "    ])\n",
    "    # Create dataset\n",
    "    dataset = CocoCaptions(\n",
    "        root=root,\n",
    "        annFile=annFile,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fdab782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\COCO2014\\\\annotations_trainval2014\\\\annotations\\\\captions_val2014.json'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1187023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "torch.Size([32, 3, 224, 224])\n",
      "[['Two people standing in a kitchen looking around. ', 'A woman covers her mouth as she is presented a birthday cake.  ', 'A white plate on a table topped with a sandwich.', 'A woman laying on a bathroom floor next to a toilet.', 'A sandwich that is sitting on a plate.', 'A young woman is walking to the ocean with her surfboard.', 'A dog catches a firsbee in the middle of the air. ', 'I am unable to see an image above.', 'An older gentleman in a white shirt and black bow tie.', 'A man riding a red surfboard on a wave in the ocean.', 'A woman holding a roasting pan filled with a turkey in an open oven.', 'A little boy walking down a street next to young men skateboarding on it.', 'An elephant reaches its trunk over a fence toward a kid. ', 'Large clock sitting on the side of a large building. ', 'A table topped with a colorful table cloth with food on top of it.', 'a tabby and black cat lounging on a sofa ', 'A woman sitting at a table with a  pizza in front of her.', 'A man in a jean jacket riding a motorcycle on a road.', 'A yellow box truck with graffiti on its side.', 'an image of a street sign on the street', 'A couple of kids standing around a red fire hydrant.', 'A woman grabbing a piece of cake off the top of a plate.', 'A city intersection at Castro street with three stoplights', 'The snowboarders are posing for a picture on the slope.', 'A clock sitting on top of a street sign.', 'Petals gather along the edge of a pond in front of two park benches.', 'Partially eaten cake on a white plate in a restaurant', 'A kitchen is shown in midst of repairs.', 'Several small electronic devices are sitting with a backpack at an airport window.', 'A airplane banking to the right as it ascends into the sky', 'A woman in red shirt standing in bathroom with sinks and a television.', 'a close up of a kitten under a parked car very close to the tire'], ['A couple of men are standing in a kitchen', 'A birthday cake with lit candles on it. ', 'A table has a camera, cup, and a plate with a sandwich on it.', 'A person is laying on their back on the floor of a bathroom.', 'A close up view of Italian mini hoagie sandwich.', 'A woman carrying a red surfboard on beach.', 'A dog jumping into the air catching a white frisbee.', 'A group of skiers in the snow in a competition.', 'A man dressed in formal wear is smiling.', 'A para-surfer is riding a large, rough wave', 'A person putting a whole chicken into an oven to cook.', 'A boy skateboards in the middle of a residential street while two friends stand nearby.', 'A small child is saying hello to an elephant', 'a very tall building with sculpture and a clock', 'Some food is on a flowered tablecloth table.', 'Two cats, one black one ginger on a dark couch.', 'a person sitting at a table with a plate of pizza ', 'a person riding a motorcycle around a curve in the road.', 'A yellow truck with graffiti painted on it.', 'Green traffic light by a road with light traffic.', 'Two girls are wearing plastic firefighter hats and standing next to a fire hydrant. ', 'Hand reaching for another piece of freshly made cake', 'A street sign on a stoplight pole in the middle of a day.', 'Two people are standing on the snow on a mountain.', 'a clock sitting on a pole with a park in the background', 'Two benches surrounded by leaves near the pond.', 'The desert is ready to be eaten on the table.', 'A picture of an unfinished back splash in the kitchen with a microwave and other small kitchen appliances.', 'Some items leaning up against a window in an airport terminal with jet outside', 'A JAL airplane is flying in the sky.', 'Black television sitting on the corner of a bathroom wall. ', 'A small grey kitten sitting under the wheel of a black car.'], ['Two people looking at a large kitchen ', 'A person holding a cake with lit candles in front of a girl in a dark room.', 'A half-eaten sandwich and coffee on a table with a camera.', 'A woman laying down on a bathroom floor by a trash can. ', 'A sandwich that has a type of meat on it.', 'A girl on the beach walking towards the water with a surf board.', 'A dog catches the frisbee while playing outside.', 'A time lapse photo of a skier skiing down a hill.', 'An older man with a white shirt and bow tie is smiling.', 'A person is hanging from a rope while riding a surfboard.', 'A woman is placing a large bird into the oven.', 'Three young people go skateboarding down a street. ', 'A girl standing in front of an elephant.', 'A large building with statues at the top of it . ', 'A table with ham, turkey and other various food entrees.', 'An orange cat is lounging on a gray couch.', 'A women who has a plate with pizza on it.', 'Motorcyclist on chromed motorcycle rounding a curve roadway.', 'A medium sized yellow cargo trucked with graffiti spray painted on the side.', 'There is a small traffic light on the street and the light is green', 'Two little girls are wearing fireman hats and poking a fire hydrant.', 'Small group of pastries being picked up off a grey plate. ', 'A bundle of overhead wires and stoplights are on Castro Street.', 'Two snowboarders celebrating their day on the slopes', 'Clock atop of street signs with buildings and parks in the background', 'Some wooden benches that are facing a pond.', 'a piece of cake is on a white plate', 'A metallic microwave oven sitting on top of a counter.', 'The words \"Connect_Anywhere\" cover a black and white photo of an unattended backpack left beside the window of an airport terminal overlooking the tarmac and a commercial airplane.', 'A commercial airplane flying on a clear day.', 'A woman photographing a television located in a swank bathroom.', 'A cat near the back of a car tire.'], ['An elderly man and woman looking around in a kitchen.', 'A birthday cake explicit in nature makes a girl laugh.', 'A half eaten sandwich sits on a table with a coffee near by.', 'a person laying on the ground in a bath room near a toilet', 'A blurry image of an Italian meatball sandwich on a plate.', 'A girl carrying a surfboard toward the water.', 'Photograph of an outdoor arena that looks neat.\\n', 'A group of men on skis in a race.', 'A man smiling wearing a white shirt and bow tie.', 'A surf boarder is riding the top of a wave.', 'Woman putting a tray of food into an oven. ', 'an image of kids playing on skateboards in the street', 'A very big elephant wanting to make friends with a little boy.', 'Statues on the second floor of a building, sitting below a clock.', 'A table set with various plates of food.', 'A cat is lying down on top of a couch with a blanket.', 'A woman that is sitting in front of a pizza.', 'A person riding a motorcycle  down a road.', \"Graffiti'ed yellow box truck sits on the lawn.\", 'A green traffic signal with traffic passing by it.', 'Two young girls in toy fire helmets looking at a fire hydrant.', 'Someone is munching off pieces of cake making a mess.', 'A green and white street sign that reads \"Castro\".', 'Two snowboarders posing on a snow covered landscape. ', 'A clock above directional street signs near a bridge and crowd of people.', 'Fallen leaves cover the ground and the water at a park with benches.', 'a plate that has a piece of cake on it', 'A microwave mounted into a wall next to unfinished cabinets without doors.', 'A photo in an airport showing a backpack and a cell phone.', 'A commercial airliner in the clear blue sky.', 'A woman stnind in a bathroom with a tv in the top corner.', 'A small kitten sits next to the rear tire of a car.'], ['Two people standing close to each other while standing in a kitchen.', 'A woman holding a glass while standing next to a cake.', 'Half eaten sandwich and a cup of coffee sitting on table in front of camera equipment.', 'A person is laying on the bathroom floor in front of toilet.', 'A closeup of a sandwich on a red plate.', 'A woman walking toward the ocean with her surf board', 'A dog jumps high in the air to catch a frisbee.', 'A group of skiers glide along the snow.', 'An elderly man wearing a white button down shirt and a black bow tie smiling.', 'A man wake boarding in the ocean behind a boat.', 'A woman placing a turkey inside an oven.', 'A male skateboarder is riding his skate board in the street along with others', 'A little girl feeding an elephant out of the palm of her hand. ', 'A large clock on the top of a building.', 'A couple of plates with food on top of a floral table cloth.', 'Two cats on a couch with one looking at you.', 'a couple of large pizzas that are on a table', 'The man is riding his motorcycle around the bend. ', 'A yellow medium size truck has graffiti on the side.', 'A green light on a traffic light at the side of a road.', 'two small children playing next to a fired hydrant and holding a balloon', 'A woman breaking off a piece of bread.', 'A sign for the Castro district among 3 lights at an intersection. ', 'A couple of people with snowboards in the snow.', 'Signs are attached to a light pole, featuring a large clock.', 'Two benches on leaf covered ground near water ', 'A piece of cake, with one slice taken out of it.', 'A microwave that is inside of the wall in a home.', 'A picture of a backpack in an airport.', 'a white airplane flies across the blue sky', 'A bathroom with a television mounted in the corner.', 'The small kitten is sitting underneath the car.']]\n"
     ]
    }
   ],
   "source": [
    "root = val_root_img\n",
    "annFile = val_captions\n",
    "dataloader = get_coco_dataloader(root = root, annFile=annFile, transform=trans_v2)\n",
    "\n",
    "# Each item will be (image, captions) where captions is a list of strings\n",
    "for images, captions in dataloader:\n",
    "    # images: tensor of shape [batch_size, 3, 224, 224]\n",
    "    # captions: list of lists, where each inner list contains 5 captions for one image\n",
    "    print(images.size())\n",
    "    print(captions)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4151c10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(captions), len(captions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "284b191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two people looking at a large kitchen ',\n",
       " 'A person holding a cake with lit candles in front of a girl in a dark room.',\n",
       " 'A half-eaten sandwich and coffee on a table with a camera.',\n",
       " 'A woman laying down on a bathroom floor by a trash can. ',\n",
       " 'A sandwich that has a type of meat on it.',\n",
       " 'A girl on the beach walking towards the water with a surf board.',\n",
       " 'A dog catches the frisbee while playing outside.',\n",
       " 'A time lapse photo of a skier skiing down a hill.',\n",
       " 'An older man with a white shirt and bow tie is smiling.',\n",
       " 'A person is hanging from a rope while riding a surfboard.',\n",
       " 'A woman is placing a large bird into the oven.',\n",
       " 'Three young people go skateboarding down a street. ',\n",
       " 'A girl standing in front of an elephant.',\n",
       " 'A large building with statues at the top of it . ',\n",
       " 'A table with ham, turkey and other various food entrees.',\n",
       " 'An orange cat is lounging on a gray couch.',\n",
       " 'A women who has a plate with pizza on it.',\n",
       " 'Motorcyclist on chromed motorcycle rounding a curve roadway.',\n",
       " 'A medium sized yellow cargo trucked with graffiti spray painted on the side.',\n",
       " 'There is a small traffic light on the street and the light is green',\n",
       " 'Two little girls are wearing fireman hats and poking a fire hydrant.',\n",
       " 'Small group of pastries being picked up off a grey plate. ',\n",
       " 'A bundle of overhead wires and stoplights are on Castro Street.',\n",
       " 'Two snowboarders celebrating their day on the slopes',\n",
       " 'Clock atop of street signs with buildings and parks in the background',\n",
       " 'Some wooden benches that are facing a pond.',\n",
       " 'a piece of cake is on a white plate',\n",
       " 'A metallic microwave oven sitting on top of a counter.',\n",
       " 'The words \"Connect_Anywhere\" cover a black and white photo of an unattended backpack left beside the window of an airport terminal overlooking the tarmac and a commercial airplane.',\n",
       " 'A commercial airplane flying on a clear day.',\n",
       " 'A woman photographing a television located in a swank bathroom.',\n",
       " 'A cat near the back of a car tire.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[caption for caption in captions[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc25925f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Two people standing in a kitchen looking around. ',\n",
       " 'A couple of men are standing in a kitchen',\n",
       " 'Two people looking at a large kitchen ',\n",
       " 'An elderly man and woman looking around in a kitchen.',\n",
       " 'Two people standing close to each other while standing in a kitchen.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[0][0], captions[1][0], captions[2][0], captions[3][0], captions[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2afad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e5feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# image = images[0]\n",
    "# print(type(image))\n",
    "# mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "# std = torch.tensor([0.229, 0.224, 0.225])\n",
    "# image = (image.permute(1, 2, 0) * std.view(1, 1, 3) + mean.view(1, 1, 3)).clamp(0, 1).byte().numpy()\n",
    "# image = Image.fromarray(image, mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb182b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO Caption: Two people standing in a kitchen looking around. , A woman covers her mouth as she is presented a birthday cake.  , A white plate on a table topped with a sandwich., A woman laying on a bathroom floor next to a toilet., A sandwich that is sitting on a plate., A young woman is walking to the ocean with her surfboard., A dog catches a firsbee in the middle of the air. , I am unable to see an image above., An older gentleman in a white shirt and black bow tie., A man riding a red surfboard on a wave in the ocean., A woman holding a roasting pan filled with a turkey in an open oven., A little boy walking down a street next to young men skateboarding on it., An elephant reaches its trunk over a fence toward a kid. , Large clock sitting on the side of a large building. , A table topped with a colorful table cloth with food on top of it., a tabby and black cat lounging on a sofa , A woman sitting at a table with a  pizza in front of her., A man in a jean jacket riding a motorcycle on a road., A yellow box truck with graffiti on its side., an image of a street sign on the street, A couple of kids standing around a red fire hydrant., A woman grabbing a piece of cake off the top of a plate., A city intersection at Castro street with three stoplights, The snowboarders are posing for a picture on the slope., A clock sitting on top of a street sign., Petals gather along the edge of a pond in front of two park benches., Partially eaten cake on a white plate in a restaurant, A kitchen is shown in midst of repairs., Several small electronic devices are sitting with a backpack at an airport window., A airplane banking to the right as it ascends into the sky, A woman in red shirt standing in bathroom with sinks and a television., a close up of a kitten under a parked car very close to the tire\n"
     ]
    }
   ],
   "source": [
    "# Image.fromarray(images[0].permute(1, 2, 0).numpy(), mode='RGB').show()\n",
    "# print(\"COCO Caption: \" + \", \".join(captions[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e2a5a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2048, 7, 7])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch0_enc = resnet152_net(images.to(device))\n",
    "batch0_enc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f06b1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 7, 7, 2048])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch0_enc = batch0_enc.permute(0, 2, 3, 1)\n",
    "batch0_enc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64b648ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 49, 2048])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch0_enc = batch0_enc.view(batch0_enc.size(0), -1, batch0_enc.size(-1))\n",
    "batch0_enc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8895dfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(caption) for sublist in captions for caption in sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e77954c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180,\n",
       " 'The words \"Connect_Anywhere\" cover a black and white photo of an unattended backpack left beside the window of an airport terminal overlooking the tarmac and a commercial airplane.',\n",
       " (2, 28))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_caption, max_indices = max(\n",
    "    ((caption, (i, j)) for i, sublist in enumerate(captions) for j, caption in enumerate(sublist)),\n",
    "    key=lambda x: len(x[0])\n",
    ")\n",
    "len(max_len_caption), max_len_caption, max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54c4a55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(caption) for caption in captions[0]]) - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
