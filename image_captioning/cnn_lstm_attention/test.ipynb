{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d773d7f4-0587-47e8-a86e-651f9021f8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Srijan\\anaconda3\\envs\\diffusion_1\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import v2\n",
    "import cv2\n",
    "from torchvision.models import (densenet121, DenseNet121_Weights,\n",
    "                                densenet161, DenseNet161_Weights,\n",
    "                                resnet50, ResNet50_Weights,\n",
    "                                resnet152, ResNet152_Weights, \n",
    "                                vgg19, VGG19_Weights)\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.datasets import CocoCaptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21bc143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\cnn_lstm_attention'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7a18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_img = \"C:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\COCO2014\\\\train2014\"\n",
    "val_root_img = \"C:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\COCO2014\\\\val2014\"\n",
    "train_captions = \"C:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\COCO2014\\\\annotations_trainval2014\\\\annotations\\\\captions_train2014.json\"\n",
    "val_captions = \"C:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\COCO2014\\\\annotations_trainval2014\\\\annotations\\\\captions_val2014.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f9792e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_album = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(224, 224, interpolation=cv2.INTER_AREA),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        A.pytorch.ToTensorV2()], p=1.\n",
    "    ),\n",
    "    \"test\": A.Compose([\n",
    "        A.Resize(224, 224, interpolation=cv2.INTER_AREA),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        A.pytorch.ToTensorV2()], p=1.\n",
    "    )\n",
    "}\n",
    "\n",
    "trans_v2 = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9208458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f3631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = Image.open(os.path.join(train_root_img, os.listdir(train_root_img)[0])).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536bcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152_net = resnet152(weights = ResNet152_Weights.DEFAULT)\n",
    "resnet152_net = nn.Sequential(*list(resnet152_net.children())[:-2]).to(device)\n",
    "resnet152_dim = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3448fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 224, 224]), torch.Size([1, 3, 224, 224]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_trans_album = trans_album[\"train\"](image = np.array(img0, dtype = np.float32))[\"image\"].to(device).unsqueeze(0)\n",
    "img0_trans_v2 = trans_v2(img0).to(device).unsqueeze(0)\n",
    "img0_trans_album.size(), img0_trans_v2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eedcced5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 7, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_res152 = resnet152_net(img0_trans_album)\n",
    "img0_res152.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2969998c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 7, 2048])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_res152 = img0_res152.permute(0, 2, 3, 1)\n",
    "img0_res152.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeeecbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 49, 2048])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_res152 = img0_res152.view(img0_res152.size(0), -1, img0_res152.size(-1))\n",
    "img0_res152.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e535cdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(albumentations.core.composition.Compose,\n",
       " torchvision.transforms.v2._container.Compose)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trans_album[\"train\"]), type(trans_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d44ca7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trans_album[\"train\"]) == A.core.composition.Compose, type(trans_v2) == v2._container.Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be122767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coco_dataloader(\n",
    "    transform,\n",
    "    root: str,\n",
    "    annFile: str,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 4\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a DataLoader for COCO Captions using torchvision's built-in dataset.\n",
    "    \n",
    "    Args:\n",
    "        root: Path to the COCO images directory\n",
    "        annFile: Path to the annotations json file\n",
    "        batch_size: Number of samples per batch\n",
    "        num_workers: Number of worker processes for data loading\n",
    "    \"\"\"\n",
    "    # Define transforms\n",
    "    transform = v2.Compose([\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "    ])\n",
    "    # Create dataset\n",
    "    dataset = CocoCaptions(\n",
    "        root=root,\n",
    "        annFile=annFile,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fdab782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Srijan\\\\Desktop\\\\Srijan\\\\seq2seq-demo\\\\image_captioning\\\\COCO2014\\\\annotations_trainval2014\\\\annotations\\\\captions_val2014.json'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1187023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "torch.Size([32, 3, 224, 224])\n",
      "[['Room with a couch, tv, dining table surrounded by chairs and two doors ', 'A player runs for the ball during a tennis match.', 'A doughnut shop sign hanging off the side of a building.', 'There are several multicolored sun umbrellas and this boy is holding one', 'A man riding a motorcycle approaching a man wearing camouflage clothing.', 'A man and two girls sitting on a couch with a dog.', 'A policeman, cameraman, and reporter stand near a police checkpoint.', 'People are horseback riding as a man is taking a picture.', 'A Penn tennis bill resting on a tennis racquet', 'The top of the head of a man sitting in front of disorganized computer desk', 'a stove top with a tea kettle with steam pouring out of it.', 'a girl smiling sitting at a table in front of several display items.', 'A group of men play frisbee in a field.', 'The young girl is sitting at the table eating a piece of cake. ', 'A train traveling down tracks next to a  brick building.', 'A man swinging a tennis racquet at a ball on a court.', 'An animal, curled into a ball, takes a nap.', 'A man swings a tennis racket and falls onto the grass.', 'A train traveling under a bridge next to other tracks.', 'A girls soccer game is in the works onthe field.', 'A long, narrow yellow kitchen with black and white floor tiles.', 'A grey cat laying down on a wooden desk.', 'A man standing next to a circus clown.', 'Banana and plastic drink container sitting on a table.', 'A couple of zebra standing next to each other.', 'Very artistic photograph of a house, a lake and a wooden boat', 'a group of people stand next to a refrigerator posing for a photo', 'A bike leaning against a sign in Scotland.', 'A man holding an apple device up to his face.', 'A bald man in a suit looking down at something ', 'A bus with passengers who are getting out of bus with their luggage at their destination.', 'A person is on a snowboard on a ramp.'], ['A couch, table, chairs and a tv are featured in a den with blue carpeting.', 'A woman reaching with her tennis racquet on a court.', 'There is a sign for doughnuts above a sign for soda pop.', 'A boy in a yellow shirt putting up multicolored umbrellas on a sidewalk. ', 'A man dressed in camouflage riding a old military style motorcycle. ', 'Dad sitting on a coach with his two daughters and a dog.', 'Policemen and reporters standing on the corner and in the street', 'A crowd of people gathered around a woman on a horse.', 'A tennis ball sitting on top of a tennis racket. ', 'A man sitting in front of a wooden desk, filled with papers and a desk top computer.', 'A tea kettle with steam coming out of the top.', 'A smiling lady at a table with boxes of pastries.', 'the group of ultimate Frisbee players try to intercept a toss', 'A girl in yellow dress eating a piece of cake on table.', 'A train approaching a railroad crossing during the day.', 'A guy in a green shirt is preparing to hit a tennis ball.', 'A puppy all curled up taking a nap.', 'A man in different poses holding a tennis racquet.', 'A train travelling under a bridge near a platform. ', 'girls soccer teams playing against each other both wear blue', 'yellow kitchen with black and white floor and pendant light.', 'A cat laying on a desk in front of books.', 'A sad clown with a patrion at the event', 'A banana is sitting beside a large bowl storage container.', 'two zebras standing and staring on a dry ground', 'a small boat floating down a river by a house', 'A picture of people posing by a fridge.', 'A bike in front of a scenic welcome sign. ', 'A smiling man holding a cell phone by his face.', 'A bald young man in a black coat and bow tie.', 'Pedestrians walking by and waiting at a food truck parked on the side of a street.', 'The ski lifts are going up the mountain.'], ['The living room is clean and empty of people.', 'A woman standing on a tennis court with a racket in her hand.', 'Two different types of signs hanging off a building.', 'A man in a yellow shirt takes down colorful umbrellas outside.', 'A man riding an old motorcycle beside an Army worker', 'Some kids are relaxing with their dad on a coach', 'A bunch of police officers on a city street corner,', 'a lady on a horse and people taking a photo', 'A blue tennis racket has a yellow tennis ball on it.', 'A man with blonde hair in front of his computer.', 'Smoke is rising from a pan on the back of the stove top.', 'The woman is sitting at the table with the deserts. ', 'A group of men on a field playing frisbee.', 'A little girl eating a piece of cake. ', 'A train track junction with a train on one of the tracks.', 'A man who is attempting to hit a tennis ball.', 'A cold dog curled up and going to sleep.', 'Still shots of a man trying to hit a shuttlecock.', 'a train is passing underneath a large bridge', 'A couple of girls playing a soccer on a field.', 'The kitchen had a yellow wall and checkered floor. ', 'A gray cat lying on top of a table', 'A clown mimicking a man on a cell phone.', 'A banana sitting on a counter next to a pitcher.', 'Two zebras are walking side by side on some grass.', 'A canoe in the water near grass and a house.', 'A group of friends stand around a refrigerator.', 'a welcome to Scotland sign with a bicycle leaning on it', 'A man holding an iPhone up to his face.', 'A man in a suit is looking down', 'The people stop for food at the lunch truck.', 'A lift on a snowy hill bordered by image of film roll.'], ['Someone recently redid their front room in blues and browns', 'A lady wearing white sneakers playing tennis on a tennis court.', 'Two different photos of signs with advertising on them.', 'A man holding up an umbrella near other umbrellas.', 'A military base with a man walking and another on a motorcycle.', 'A group of people that are sitting on the couch.', 'A street corner with several police officers standing', 'A woman riding on the back of a brown horse.', 'A tennis ball is sitting on a tennis racket.', 'A man with blonde hair sitting at a computer desk with a desktop computer.', 'a kitchen with a tea pot on a stove', 'A young girl sitting at a table with a box of doughnuts', 'A group of people on a field with a Frisbee.', 'a girl eating a piece of cake from a pink princess plate ', 'A train is approaching a train signal in an area with several tracks.', 'A male tennis player hitting a tennis ball. ', 'A short haired dog curled up sleeping contently.', 'Several motion shots of a man playing tennis.', 'A train on the tracks under a walkway from one building to the next ', 'Two girls on a soccer team chasing after a ball.', 'a yellow walled kitchen with a black and white checkered floor', 'A cat laying on a desk in a home office ', 'A guy standing next to a sad clown.', 'A banana and a container with a lid on a counter.', 'A couple of zebras are standing in the dirt', 'A body of calm water with a wooden canoe docked on the side and a home across the water.', 'People posing with a white two door refrigerator', 'Bicycle leaning up against a welcome to Scotland sign.', 'A guy is posing for the camera with his IPOD. ', 'The man in the tuxedo is also bald headed.', 'People standing and walking by a food truck parked on the street.', 'A person on a snowboard jumping off a pile of snow.'], ['An empty living room with many pieces of furniture. ', 'A woman vigorously plays tennis by running off the court.', 'two older signs hung from the side of a building advertising pepsi and donuts', 'A man holding a multi colored umbrella next to several other multi colored umbrellas.', 'a man that is riding around on a motorcycle', 'a man two girls and a brown and black dog ', 'Camera men are filming a woman standing by the street.', 'A woman is riding a horse with several women doing the same.', 'A tennis ball sitting on a tennis racket.', 'A man looks away from the camera as he sits at his messy desk. ', 'a tea pot is steaming on the stove top', 'A woman smiling next to two boxes of donuts.', 'Several young men are competing over the Frisbee. ', 'A person sitting at a table with some food.', 'A train drives down rail road tracks next to a brick building.', 'A tennis player is swinging at a tennis ball on a sunny day. ', 'A small brown dog curled up in sleep.', 'A man is swinging his tennis racket on a grassy area.', 'a green and yellow train some tracks and a bridge', 'Young girls prepare to get the ball as they play in a soccer match.', 'A kitchen scene with yellow walls and a checkered floor pattern.', 'A fat cat laying on the edge of a desk.', 'A man in clown makeup next to man on cellphone.', 'A banana laying next to a plastic container with lid.', \"A couple of zebra's with a side view of them standing in a field.\", 'a house sits next to a swampy river ', 'Four people posing near a large white refrigerator.', 'A sign for a village in Scotland with a bicycle in front of it.', 'A bearded man with glasses is holding an iPhone. ', 'A bald headed man looking down and he is wearing a suit.', 'A group of people on a street next to a food truck.', 'a person jumping a snow board in the air']]\n"
     ]
    }
   ],
   "source": [
    "root = val_root_img\n",
    "annFile = val_captions\n",
    "dataloader = get_coco_dataloader(root = root, annFile=annFile, transform=trans_v2)\n",
    "\n",
    "# Each item will be (image, captions) where captions is a list of strings\n",
    "for images, captions in dataloader:\n",
    "    # images: tensor of shape [batch_size, 3, 224, 224]\n",
    "    # captions: list of lists, where each inner list contains 5 captions for one image\n",
    "    print(images.size())\n",
    "    print(captions)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4151c10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(captions), len(captions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "284b191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The living room is clean and empty of people.',\n",
       " 'A woman standing on a tennis court with a racket in her hand.',\n",
       " 'Two different types of signs hanging off a building.',\n",
       " 'A man in a yellow shirt takes down colorful umbrellas outside.',\n",
       " 'A man riding an old motorcycle beside an Army worker',\n",
       " 'Some kids are relaxing with their dad on a coach',\n",
       " 'A bunch of police officers on a city street corner,',\n",
       " 'a lady on a horse and people taking a photo',\n",
       " 'A blue tennis racket has a yellow tennis ball on it.',\n",
       " 'A man with blonde hair in front of his computer.',\n",
       " 'Smoke is rising from a pan on the back of the stove top.',\n",
       " 'The woman is sitting at the table with the deserts. ',\n",
       " 'A group of men on a field playing frisbee.',\n",
       " 'A little girl eating a piece of cake. ',\n",
       " 'A train track junction with a train on one of the tracks.',\n",
       " 'A man who is attempting to hit a tennis ball.',\n",
       " 'A cold dog curled up and going to sleep.',\n",
       " 'Still shots of a man trying to hit a shuttlecock.',\n",
       " 'a train is passing underneath a large bridge',\n",
       " 'A couple of girls playing a soccer on a field.',\n",
       " 'The kitchen had a yellow wall and checkered floor. ',\n",
       " 'A gray cat lying on top of a table',\n",
       " 'A clown mimicking a man on a cell phone.',\n",
       " 'A banana sitting on a counter next to a pitcher.',\n",
       " 'Two zebras are walking side by side on some grass.',\n",
       " 'A canoe in the water near grass and a house.',\n",
       " 'A group of friends stand around a refrigerator.',\n",
       " 'a welcome to Scotland sign with a bicycle leaning on it',\n",
       " 'A man holding an iPhone up to his face.',\n",
       " 'A man in a suit is looking down',\n",
       " 'The people stop for food at the lunch truck.',\n",
       " 'A lift on a snowy hill bordered by image of film roll.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[caption for caption in captions[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc25925f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Room with a couch, tv, dining table surrounded by chairs and two doors ',\n",
       " 'A couch, table, chairs and a tv are featured in a den with blue carpeting.',\n",
       " 'The living room is clean and empty of people.',\n",
       " 'Someone recently redid their front room in blues and browns',\n",
       " 'An empty living room with many pieces of furniture. ')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[0][0], captions[1][0], captions[2][0], captions[3][0], captions[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd2afad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b49e5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = images[0]\n",
    "# print(type(image))\n",
    "# mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "# std = torch.tensor([0.229, 0.224, 0.225])\n",
    "# image = (image.permute(1, 2, 0) * std.view(1, 1, 3) + mean.view(1, 1, 3)).clamp(0, 1).byte().numpy()\n",
    "# image = Image.fromarray(image, mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bb182b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image.fromarray(images[0].permute(1, 2, 0).numpy(), mode='RGB').show()\n",
    "# print(\"COCO Caption: \" + \", \".join(captions[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e2a5a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2048, 7, 7])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch0_enc = resnet152_net(images.to(device))\n",
    "batch0_enc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f06b1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 7, 7, 2048])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch0_enc = batch0_enc.permute(0, 2, 3, 1)\n",
    "batch0_enc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64b648ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 49, 2048])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch0_enc = batch0_enc.view(batch0_enc.size(0), -1, batch0_enc.size(-1))\n",
    "batch0_enc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8895dfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(caption) for sublist in captions for caption in sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e77954c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89,\n",
       " 'A bus with passengers who are getting out of bus with their luggage at their destination.',\n",
       " (0, 30))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_caption, max_indices = max(\n",
    "    ((caption, (i, j)) for i, sublist in enumerate(captions) for j, caption in enumerate(sublist)),\n",
    "    key=lambda x: len(x[0])\n",
    ")\n",
    "len(max_len_caption), max_len_caption, max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54c4a55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(caption) for caption in captions[0]]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a044d7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch0_enc.dim()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
